
We thank the referee for the careful reading and many valuable comments. Here we attached the updated draft
where important changes are highlighted in cyan.

We believe that all the comments and questions from the referee have been addressed, and below are the
detailed response to some of the referee's concerns.  

-----
0. About the general comment that this draft resembles a "technical supplement of the hscPipe paper", we
think:
    * SynPipe paper presents important evaluations of the curent HSC data.  These results are useful to
      the general users of HSC instrument.  Given that the hscPipe paper already contains lots of technical 
      details and is quite long, we believe that a separate paper can better draw people's attention to these
      results. 
    * As we now presented in the new Discussion section, as an independent software, SynPipe is being used for
      many scientific goals, both within and outside the SSP community.  For some of them (e.g. Murata et al.
      in prep. about the impact of blended objects in weak lensing analysis), SynPipe is the key technical
      component.  We think it is useful to have a separate paper as reference to the readers of these works
      and the future SynPipe users.  In addition, SynPipe has recently been adopted by the LSST community, and 
      will be used to test the performance of the LSST pipeline.  We think it is useful to summarize the
      developement of SynPipe on the HSC side as an independent paper. 
    * We would like to draw the referee's attention to papers with the similar purpose, e.g. Balrog for the
      DES survey (http://adsabs.harvard.edu/abs/2016MNRAS.457..786S). These papers are proved to be useful and
      well-cited for similar reasons as we stated above. 

----- 

# 1. Discussion: 

We agree with the referee that this work can benefit from a more detailed discussion, which we have added
before the Summary section.  A few relevant points were included in the earlier Summary and Conclusion
section, and have been moved to the new Discussion section.  

We emphasize the importance of such synthetic object pipeline for modern cosmology survey, explain again the
philosophy of our desgin, and compare it with other efforts for testing the data reduction pipline.  
Right now, SynPipe is specifically tailored for HSC images, but it will be included in the LSSTpipe in the
near future.  We demonstrate the broad scientific topics that can benefit from SynPipe, and describe the
on-going efforts for further improvements. 

-----
# 2 Interpreter Language

The referee is correct that, in general, C++ should be more efficient in the heavy duty data reduction process.
However, SynPipe here mainly works as a special user interface to hscPipe, which is also use Python for
high-level algorithm.  The reason for this choise is described in details in the Section 2 of the technical paper 
for hscPipe (Bosch et al. 2017).  Below is the most relevant paragraph: 

    """
    Both the LSST Data Management codebase and the HSC Pipeline are written in a combination of C++ and Python. 
    Flexibility and extensibility are core development goals at all levels of the code-base: we have attempted 
    to make virtually every algorithm not just configurable but replaceable (even by external code). 
    This flexibility is important for LSST in part because many algorithmic choices in LSST processing still 
    require significant research and are under active development.....
    
    High-level algorithms are written in Python, primarily as subclasses of our Task class...

    Low-level algorithms that perform direct pixel-level processing or other computationally intensive operations 
    are written in C++....
    """

As the referee can see, flexibility and extensibility is the main reason that hscPipe choose to use Python as
the high-level language.  GalSim also uses the same logic.  Since SynPipe 1) directly depends on hscPipe and
GalSim; 2) will develop along with the hscPipe (and LSSTpipe in the future); 3) does not do any low-level
computationally intensive operation, we think it is natural to follow this decision and use Python as our
working language. 

The efficiency of SynPipe, as the referee mentioned, certaintly relates to the available cores of the CPU. 
What we meant to explain is that, under the same computational condition, SynPipe test costs similar amount
time as the real data reduction.  Most heavy duty is carried out by hscPipe, so using C or C++ for SynPipe
will not increase the efficiency.  The most time-consuming part of SynPipe test is the injection of synthetic
objects to the individual CCD image.  During this process, the most computationally intensive part is carried
out by GalSim using C++, so using C or C++ for SynPipe here will not increase the efficiency much.  At the
end, we would like to emphasize that the design of SynPipe currently focuses on testing data reduction in the
most reaslistic way, in the future, we will gradually work on increase the efficiency of SynPipe. 

Following the suggestion by the referee, we now try to explain this better in Section 2.2, 
Section 3.1, and Section 3.2.3.  

-----
# 3.  Missing Definitions 

The referee is correct that some of these basic definitions should be explained better.  
Most of these concepts are explained and discussed in great details in the hscPipe paper (Bosch et al. 2017)
and the Data Release 1 Paper (Aihara et al. 2017).  We emphasize the basic definitions of these values at the
end of the introduction section and point the authors to the Bosch+2017 paper for more details. 

<1> HSC pipeline performs multi-step photometric calibrations against the Pan-STARRS system, hence all the
fluxes and magnitudes measured by hscPipe are already calibrated into the AB magnitude system.  Therefore, the
pixel values on the calibrated single-Visit and coadd images can be directly related to fluxes in physical
unit, and can be converted into magnitudes using a simple calibration zeropoint (27.0).  Users of HSC survey
data should not worry that the definition of magnitude is affected by filter or exposure time.
Through out this work, we assume that all magnitudes of synthetic objects are also in AB system, and they are 
converted into fluxes using the same zeropoint.  

<2> The CCD processing provides us calibrated exposures that include both the detrended, background-subtracted
image and an image containing per-pixel estimate of the variance. The following coaddition process also takes
the variance information into account, uses the inverse of the mean variance of the input images to set the
weights for coaddition, and calculates the per-pixel variance for the coadd images. Both the PSF and CModel
photometry take these variance images into account, and provide meaningful estimations of flux error for the
coadd images.  
    - The HSC pipeline uses matched-filter method to estimate the PSF fluxes.  Per-pixel variance information
      is taken into account when estimating the flux error.  Please see Section 4.9.5 of Bosch+2017 for more
      technical details.  
    - The HSC CModel photometry is modified and improved based on the SDSS version.  It fits linear
      combination of two basic parametric models to the 2-D flux distribution of galaxy after taking PSF
      convolution into account.  It has the advantage of providing consistent multiband photometry for
      extended objects and having reliable performance for very faint object. 
      Please see Section 4.9.9 and Appendix 2 of Bosch+2017 for technical details of the CModel algorithm. 
    - For CModel photometry, it is optional to use per-pixel inverse square root of the variance information
      as weights during the fitting (when usePixelWeights=True).  By default, usePixelWeights=False, and a
      constant weight is used for an object.  Again we will refer the reader to Bosch+2017 for more details
      about this. 

<3> We understand the referee's concern, and it is true that based on statistics of photons, we could have
more clear definition of signal-to-noise ratio (S/N).  However, in practice, it is not realistic to use "photon
number" for statistics or separately account for the noise from readout, dark, and sky background.  Each CCD
on the camira has four amplifiers that have slightly different effective gain; individual CCD images need to
be detrended, calibrated, and background subtracted before coaddition; single exposures with different seeings
are warped before they are coadded into a final image using appropriate weighting.  All these processes make
it difficult to trace back to the origianl photon statistics.  For instance, on the coadd image, there are
covariances between adjacent pixels due to the warping process.  On the other hand, hscPipe calibrates the
pixels values on both coadd and single-Visit images to physically meaningful flux scale, and provides
correponding variance information that reflect the per-pixel uncertainties after all these complex reduction
steps.  Based on this design, scientific user of HSC data can use the flux value and its uncertainty from
hscPipe to estimate the S/N of the object under certain photometric method.  
    - Throughout this work, S/N is defined as the ration between a flux measurement and its uncertainty (flux
      / flux_err).  Same definition is adopted by both Bosch+2017 (hscPipe paper) and Aihara+2017 (HSC DR1
      paper), along with a series of science papers.  
    - Under this definition, 5 sigma detection corresponds to a S/N=5 flux measurement under certain
      photometric method.  The same concept is adopted by both Bosch+2017 (hscPipe paper) and Aihara+2017 
      (HSC DR1 paper), along with a series of science papers. 
    - Both the PSF and CModel photometry algorithms convolve a model for the true objectâ€™s morphology with 
      the effective PSF model at the position of the object, which maximizes S/N (see Bosch+2017)

The changes of text related to this comment are: 
    - At the end of Introduction section, we make it clear that we are using AB system, and explain the
      definiton of S/N and Nxsigma detection.  
    - At the end of Section 2.2, we provide more details related to the flux measurements for PSF and CModel
      photometry.  We also refer the reader to Bosch+2017 for more technical details. 
    - Section 6.4: slightly more details about the usePixelWeights option and reference to hscPipe paper. 

-----
# 4. CModel algorithm

We agree with the referee that the details of CModel algorithm should be explained better.  However, limited
by the scope of this work, we can not afford to show all the technical details.  As mentioned, we expanded 

-----
# 8. p. 7-8: "High level reduction pipeline": as stated more clearly in the hscPipe technical paper (Bosch et
al. 2017). Low-level reduction involves basic image detrending and calibration; high-level processes involves
the ones that generate coadded images and science-ready catalogs.  Now use the same explanation here to be
consistent with the technical paper and provide more details. 

-----
# 9. "purity and completeness"

-----
# Minor comments: 

1. p.7: should be 'mas' not 'max', corrected.

2. p.10, about 'rectangular cutout': the images are stored in a 2-D array, hence has a rectangular nature to
it.  And, it is much easier to convolve the model and shift the 2-D rectangular array before we add them to
the HSC coadd images.  When we generate the model image array using GalSim, we try to make sure that all fluxes 
of the model is contained in the image. For galaxies, we cutout the model at 10 x Re of the Sersic model. This 
is fine for most galaxies, but still miss small fraction of light for galaxy with very high Sersic index.
First, we try to avoide model with very high Sersic index in the input catalog, as they are often problematic
models for real galaxies; Second, given the magnitude distribution of the model galaxies (most have i>23.0
mag), the results we are showing here are not sensitive to the flux distributions outside 10 x Re.  
The referee is correct that estimation of R_e could be sensitive to the very outskirt when Sersic index is
high, but we'd like to point out that the CModel method used in hscPipe does not use any pixel with
S/N < 5, and only provides n=4 model fits (dev) to the "footprint" of the galaxy.  We do not expect accurate
R_e estimates for high Sersic index galaxies in the beginning. 

We add a footnote to briefly explain this choice. 

3. p.11, about "noise": it is Poisson noise, and we state that clearly in the text. 

4. p.13: We think the location and context of this figure makes it very clear that it is for the input
parameters.  Now we state that clearly in the caption. 

5. Fig. 4 and 5: has been corrected.

6. 
